https://towardsdatascience.com/gradient-descent-in-a-nutshell-eaf8c18212f0
https://www.datacamp.com/courses/deep-learning-in-python?tap_a=5644-dce66f&tap_s=210732-9d6bbf
https://stackoverflow.com/questions/48994440/execute-a-function-after-flask-returns-response
NER Builder
import time
import os
import json
import random
import numpy as np
from keras.preprocessing.sequence import pad_sequences
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.models import model_from_json
from keras.layers import LSTM
from keras.layers.embeddings import Embedding
from keras.callbacks import ModelCheckpoint
from keras.layers import Merge
from keras.layers import TimeDistributed
from keras.layers import Dense
from keras.layers.core import Activation
from sklearn.metrics import confusion_matrix, accuracy_score

filepath = "data/"
model_file_name = filepath+"model.json"
weight_filename = filepath+"weights-improvement-07-0.3528.hdf5"

class NER_Model_Builder:
    def __init__(self):
        start_time = time.time()
        if os.path.isfile(filepath + "char_to_int") and os.stat(filepath + "char_to_int").st_size > 0:
            self.char_to_int = json.load(open(filepath + "char_to_int"))
            self.int_to_char = json.load(open(filepath + "int_to_char"))
        else:
            self.char_to_int,self.int_to_char = self.get_char_to_int()
        if os.path.isfile(filepath + "ind2label") and os.stat(filepath + "ind2label").st_size > 0:
            self.ind2label = json.load(open(filepath + "ind2label"))
            self.label2ind = json.load(open(filepath + "label2ind"))
            self.maxlen = json.load(open(filepath + "maxlen"))
        else:
            self.ind2label,self.label2ind,self.maxlen = self.get_ind2label()
        self.batch_size = 32
        self.max_features = len(self.char_to_int)
        self.embedding_size = 128
        self.hidden_size = 32
        self.out_size = len(self.label2ind) + 1
        self.max_label = max(self.label2ind.values()) + 1
        self.num_epochs = 3
        print("initialisation time for NER Builder: %s seconds." % (time.time() - start_time))

    def get_ind2label(self):
        all_x,all_y = self.get_training_data()
        lengths = [len(x) for x in all_x]
        labels = list(set([c for tmp_y in all_y for c in tmp_y]))
        label2ind = {label: (index + 1) for index, label in enumerate(labels)}
        ind2label = {(index + 1): label for index, label in enumerate(labels)}
        with open(filepath + "label2ind", "w") as f:
            json.dump(label2ind, f)
        with open(filepath + "ind2label", "w") as f:
            json.dump(ind2label, f)
        maxlen = max(lengths)
        with open(filepath + "maxlen", "w") as f:
            json.dump(maxlen, f)
        return ind2label,label2ind,maxlen


    def get_char_to_int(self):
        raw_text = ",+#$%-&*@:.'/|(abcdefghijklmnopqrstuvwxyz0123456789) "
        chars = sorted(list(set(raw_text)))
        char_to_int = dict((c, i+1) for i, c in enumerate(chars))
        char_to_int["undetected"] = 0
        int_to_char = dict((i+1, c) for i, c in enumerate(chars))
        int_to_char[0] = "undetected"
        with open(filepath+"char_to_int","w") as f:
            json.dump(char_to_int,f)
        with open(filepath+"int_to_char","w") as f:
            json.dump(int_to_char,f)
        return (char_to_int,int_to_char)

    def get_training_data(self):
        all_x = []
        all_y = []
        skills_list = json.load(open("data/skills_data"))
        all_x,all_y = self.convert_list_string_to_char_vec(skills_list,"skill",all_x,all_y)
        role_list = json.load(open("data/role_data"))
        all_x, all_y = self.convert_list_string_to_char_vec(role_list, "role", all_x, all_y)
        others = json.load(open("data/other_data"))
        others = random.sample(others, int(len(skills_list) * 1.5))
        all_x, all_y = self.convert_list_string_to_char_vec(others, "o", all_x, all_y)
        return all_x,all_y

    def convert_list_string_to_char_vec(self,list_string,tag_label,input_x,input_y):
        for ls in list_string:
            try:
                if len(ls)>self.maxlen:
                    new_ls = ls[:self.maxlen]
                else:
                    new_ls = ls
            except:
                new_ls = ls
            new_x = [self.char_to_int[tmp_s.lower()] if tmp_s.lower() in self.char_to_int.keys() else self.char_to_int["undetected"] for tmp_s in new_ls.strip()]
            input_x.append(new_x)
            input_y.append([tag_label]*len(new_ls))
        return input_x,input_y

    def encode(self, x, n):
        result = np.zeros(n)
        result[x] = 1
        return result

    def train_model(self):
        program_start_time = time.time()
        all_x,all_y = self.get_training_data()
        print("data fetch time: %s seconds." % (time.time() - program_start_time))
        (X_train_f, X_test_f, X_train_b, X_test_b, y_train, y_test) = self.convert_training_data_to_pad_format(all_x,all_y)
        print('Training and testing tensor shapes:')
        print(X_train_f.shape, X_test_f.shape, X_train_b.shape, X_test_b.shape, y_train.shape, y_test.shape)
        print("data split time: %s seconds." % (time.time() - program_start_time))
        model = self.get_model_structure()
        model.compile(loss='categorical_crossentropy', optimizer='adam')
        callbacks_list = self.get_callback_list()
        print("model fetch time: %s seconds." % (time.time() - program_start_time))
        model.fit([X_train_f, X_train_b], y_train, epochs=self.num_epochs, batch_size=self.batch_size,
                  callbacks=callbacks_list, shuffle=True, validation_data=([X_test_f, X_test_b], y_test))
        print("model fit time: %s seconds." % (time.time() - program_start_time))
        score = model.evaluate([X_test_f, X_test_b], y_test, batch_size=self.batch_size)
        print('Raw test score:', score)
        pr = model.predict_classes([X_train_f, X_train_b])
        yh = y_train.argmax(2)
        fyh, fpr = self.score(yh, pr)
        print('Training accuracy:', accuracy_score(fyh, fpr))
        print('Training confusion matrix:')
        print(confusion_matrix(fyh, fpr))
        pr = model.predict_classes([X_test_f, X_test_b])
        yh = y_test.argmax(2)
        fyh, fpr = self.score(yh, pr)
        print('Testing accuracy:', accuracy_score(fyh, fpr))
        print('Testing confusion matrix:')
        print(confusion_matrix(fyh, fpr))
        if not ((os.path.isfile(model_file_name) and os.stat(model_file_name).st_size > 0)):
            self.save_model(model)

    def save_model(self,model):
        model_json = model.to_json()
        with open(model_file_name, "w") as json_file:
            json_file.write(model_json)

    def get_callback_list(self):
        w_filename = filepath + "weights-improvement-{epoch:02d}-{val_loss:.4f}.hdf5"
        checkpoint = ModelCheckpoint(w_filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')
        return [checkpoint]

    def convert_training_data_to_pad_format(self,all_x,all_y):
        X_enc = all_x
        X_enc_reverse = [[c for c in reversed(x)] for x in X_enc]
        max_label = max(self.label2ind.values()) + 1
        y_enc = [[0] * (self.maxlen - len(ey)) + [self.label2ind[c] for c in ey] for ey in all_y]
        y_enc = [[self.encode(c, max_label) for c in ey] for ey in y_enc]
        X_enc_f = pad_sequences(X_enc, maxlen=self.maxlen)
        X_enc_b = pad_sequences(X_enc_reverse, maxlen=self.maxlen)
        y_enc = pad_sequences(y_enc, maxlen=self.maxlen)
        return train_test_split(X_enc_f, X_enc_b, y_enc, random_state=42)

    def get_model_structure(self):
        if os.path.isfile(model_file_name) and os.stat(model_file_name).st_size > 0:
            json_file = open(model_file_name, 'r')
            loaded_model_json = json_file.read()
            json_file.close()
            model = model_from_json(loaded_model_json)
            if os.path.isfile(weight_filename) and os.stat(weight_filename).st_size > 0:
                model.load_weights(weight_filename)
        else:
            #forward mode
            model_forward = Sequential()
            model_forward.add(Embedding(self.max_features, self.embedding_size, input_length=self.maxlen, mask_zero=True))
            model_forward.add(LSTM(self.hidden_size, return_sequences=True))
            #backward model
            model_backward = Sequential()
            model_backward.add(Embedding(self.max_features, self.embedding_size, input_length=self.maxlen, mask_zero=True))
            model_backward.add(LSTM(self.hidden_size, return_sequences=True))
            #bidirectional lstm embedded model
            model = Sequential()
            model.add(Merge([model_forward, model_backward], mode='concat'))
            model.add(TimeDistributed(Dense(self.out_size)))
            model.add(Activation('softmax'))
        return model

    def score(self, yh, pr):
        coords = [np.where(yhh > 0)[0][0] for yhh in yh]
        yh = [yhh[co:] for yhh, co in zip(yh, coords)]
        ypr = [prr[co:] for prr, co in zip(pr, coords)]
        fyh = [c for row in yh for c in row]
        fpr = [c for row in ypr for c in row]
        return fyh, fpr

if __name__ == "__main__":
    obj = NER_Model_Builder()
    obj.train_model()
