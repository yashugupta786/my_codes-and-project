{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled30.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYvNjiiQF/hPmQ20N6hwKo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashugupta786/my_codes-and-project/blob/master/word_2vec_shape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jf2rmtusPcl"
      },
      "source": [
        "import itertools\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "# from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# # Deep learning: \n",
        "# from tensorflow.keras.models import Input\n",
        "# from tensorflow.keras.layers import Dense\n",
        "\n",
        "from scipy import sparse\n",
        "\n",
        "# Custom functions\n",
        "from utility import text_preprocessing,create_unique_word_dict"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whWrOvgssjEm"
      },
      "source": [
        "texts1 = pd.read_csv('sample.csv')\n",
        "texts2 = [x for x in texts1['text']]\n",
        "\n",
        "# Defining the window for context\n",
        "window = 2\n",
        "\n",
        "# Creating a placeholder for the scanning of the word list\n",
        "word_lists = []\n",
        "all_text = []\n",
        "\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RRIyjQFuwdO"
      },
      "source": [
        "\n",
        "texts=texts2[0:2]"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLlxYcYouzll"
      },
      "source": [
        "for text in texts:\n",
        "\n",
        "    # Cleaning the text\n",
        "    text = text_preprocessing(text)\n",
        "\n",
        "    # Appending to the all text list\n",
        "    all_text += text \n",
        "\n",
        "    # Creating a context dictionary\n",
        "    for i, word in enumerate(text):\n",
        "        for w in range(window):\n",
        "            # Getting the context that is ahead by *window* words\n",
        "            if i + 1 + w < len(text): \n",
        "                word_lists.append([word] + [text[(i + 1 + w)]])\n",
        "            # Getting the context that is behind by *window* words    \n",
        "            if i - w - 1 >= 0:\n",
        "                word_lists.append([word] + [text[(i - w - 1)]])\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wrd0TvR_u8B3",
        "outputId": "3624777d-231c-4b79-e3e3-ab4ce7b38c14"
      },
      "source": [
        "word_lists"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['future', 'king'],\n",
              " ['future', 'prince'],\n",
              " ['king', 'prince'],\n",
              " ['king', 'future'],\n",
              " ['prince', 'king'],\n",
              " ['prince', 'future'],\n",
              " ['daughter', 'princess'],\n",
              " ['princess', 'daughter']]"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDeymLohu-RQ",
        "outputId": "748826c9-00b7-460c-ddf3-fb554148bb0e"
      },
      "source": [
        "unique_word_dict = create_unique_word_dict(all_text)\n",
        "unique_word_dict"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'daughter': 0, 'future': 1, 'king': 2, 'prince': 3, 'princess': 4}"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIx-n80fv2Bl",
        "outputId": "ad48ee1d-d18d-4a1e-ac8a-d81cb5e30784"
      },
      "source": [
        "n_words = len(unique_word_dict)\n",
        "print(n_words)\n",
        "\n",
        "# Getting all the unique words \n",
        "words = list(unique_word_dict.keys())\n",
        "\n",
        "# Creating the X and Y matrices using one hot encoding\n",
        "X = []\n",
        "Y = []"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-Bx9zVswAp2",
        "outputId": "0c96aeb8-11f2-4a05-c8cd-7e7355ddf57d"
      },
      "source": [
        "for i, word_list in tqdm(enumerate(word_lists)):\n",
        "    # Getting the indices\n",
        "    main_word_index = unique_word_dict.get(word_list[0])\n",
        "    context_word_index = unique_word_dict.get(word_list[1])\n",
        "\n",
        "    # Creating the placeholders   \n",
        "    X_row = np.zeros(n_words)\n",
        "    Y_row = np.zeros(n_words)\n",
        "\n",
        "    # One hot encoding the main word\n",
        "    X_row[main_word_index] = 1\n",
        "\n",
        "    # One hot encoding the Y matrix words \n",
        "    Y_row[context_word_index] = 1\n",
        "\n",
        "    # Appending to the main matrices\n",
        "    X.append(X_row)\n",
        "    Y.append(Y_row)\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "8it [00:00, 11785.89it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrdtzjKgwKXt",
        "outputId": "ff34bdfb-33f9-42db-c564-02c31f25831d"
      },
      "source": [
        "X,Y"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([array([0., 1., 0., 0., 0.]),\n",
              "  array([0., 1., 0., 0., 0.]),\n",
              "  array([0., 0., 1., 0., 0.]),\n",
              "  array([0., 0., 1., 0., 0.]),\n",
              "  array([0., 0., 0., 1., 0.]),\n",
              "  array([0., 0., 0., 1., 0.]),\n",
              "  array([1., 0., 0., 0., 0.]),\n",
              "  array([0., 0., 0., 0., 1.])],\n",
              " [array([0., 0., 1., 0., 0.]),\n",
              "  array([0., 0., 0., 1., 0.]),\n",
              "  array([0., 0., 0., 1., 0.]),\n",
              "  array([0., 1., 0., 0., 0.]),\n",
              "  array([0., 0., 1., 0., 0.]),\n",
              "  array([0., 1., 0., 0., 0.]),\n",
              "  array([0., 0., 0., 0., 1.]),\n",
              "  array([1., 0., 0., 0., 0.])])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd6qY7TQwMjh"
      },
      "source": [
        "X = sparse.csr_matrix(X)\n",
        "Y = sparse.csr_matrix(Y)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqmQBWETwWUq",
        "outputId": "ad59c5a0-44ea-4eab-ccb4-66b7bc7dd817"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lquYMAoewXJm",
        "outputId": "80a67e67-689d-4be1-b086-44c0a6ed9f30"
      },
      "source": [
        "embed_size = 2\n",
        "\n",
        "# Defining the neural network\n",
        "inp = Input(shape=(X.shape[1],))\n",
        "x = Dense(units=embed_size, activation='linear')(inp)\n",
        "x = Dense(units=Y.shape[1], activation='softmax')(x)\n",
        "model = Model(inputs=inp, outputs=x)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam')\n",
        "model.summary()\n",
        "# Optimizing the network weights\n",
        "# model.fit(\n",
        "#     x=X, \n",
        "#     y=Y, \n",
        "#     batch_size=256,\n",
        "#     epochs=100)\n"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 5)]               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 12        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 15        \n",
            "=================================================================\n",
            "Total params: 27\n",
            "Trainable params: 27\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI4Qi7hTwzaz"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}